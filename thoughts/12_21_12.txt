
Fri Dec 21 10:59:44 EST 2012

Added concretization to haskellf.

Now things are looking good.

No more timeouts.

In many cases we do much better than hampi.
In many cases... hampi does better than us.

Well then... Where is all the time going? Can we make shampi better?

Especially on the ones rhampi can do well that we can't.
I suppose it makes most sense to target the harder test benches that rhampi
does well on that we don't. Yes. That makes sense to me.

I'll do my profiling. Try to figure out what's up. Try to figure out how I can
improve things.

Let's look at some benchmarks.

Fri Dec 21 11:08:24 EST 2012

Looks like perf4 is still hard for us. 
It takes us 8.9 seconds. It takes hampi 0.3 seconds.

This will be a good benchmark to understand, because it's one I've already
been looking at a lot for performance.

Let me start by scaling up. May as well scale up the whole way.

Fri Dec 21 11:12:15 EST 2012

Interesting...

* assert dominates the runtime: 45%. With basically no allocation.
* convert follows closely: 19.2%. With basically no allocation.

So, 65% of the time is dealing with the assertion predicate.

After that, compare, and tree lookup, and all that seems to dominate.

Let me look into the primary concern here. Why so much time in assert?
And in convert? Can I isolate those somehow? They are black boxes in the
profile currently.

Fri Dec 21 11:25:23 EST 2012

Okay!

* convert.lookup is slow.
So, have an auxiliary set to help us figure out what conversions we've already
done. That's an easy improvement. That should fix the convert troubles.

* runCmds is slow.
Why? Could be... a really big query? Let me see how big it is.

170M. That's a big query.

Hmm...

So there are two approaches to take here. I think it's worth trying both.

The easiest approach first is:
* Try to make convert.lookup and runCmds faster.

For convert.lookup: add this additional set. I'll do this anyway.
For runCmds......
ytermS should use a Map instead of a list for the shared variables.

It could also use a hash table to make looking up primitives faster (and
probably clean up the code too).

So I'll do these. Because they are easy, not messy, and should help a bunch.

The real approach is:
* Perhaps there is a bug in sharing.
This might lead to an exponential blowup where we shouldn't have some.
Or perhaps there is more sharing we are somehow not capturing.

This is hard to figure out. But it will make a huge difference if I can show
it's the case.

Okay, so I'll do the easy things first, then, probably after lunch, try and
understand the sharing issue.

Note: none of this is responsible for the huge memory overhead, which is
probably responsible for a lot of time too.

Fri Dec 21 12:06:09 EST 2012

Well... with those simple changes, all the troubles with conversion and
transmission of the query have gone away. All the time now is back to shampi
stuff.

That's cool... Maybe I don't even have to worry about sharing in the generated
query? Figure out where all the allocation is coming from...

Fri Dec 21 12:38:39 EST 2012

Looked at overall benchmarks. It's interesting that the test I'm looking at
got way better, but the others didn't get so much better...

Anyway, this is still a test we do poorly on, so let me continue my
investigations.

Where is all the memory and time from?

80% of the time and allocations are in the seri code. Let me see if I can
break it down a little better.

60% of time and allocation are in lookup_cache.
That's the primary contender.

50% of time and allocation are in compare.
Though a big chunk of allocation is in lookup_cache outside of that too.

Let me look into compare... Which compare is costing us?

Aha! Look at that. compare.Integer is taking 38% of the entire program time.
And 20% of the allocations.

Compare.SubMatch is taking up 13% of the program time, and 23% of the
allocations.

This is a bit surprising, don't you think?

compare.Integer: hypothesis is we do boxing/unboxing for primitives that we
ought not to have to do. It's just a little annoying to reimplement all the
primitives again for haskellf... Maybe it's not so bad?

compare.SubMatch... what allocation does this take? Why would it take any?
What kind of thing is being allocated?

Oh. Now that's an interesting question. What is making up all this allocation?
It's probably ExpH.

Oh oh ho! Look at this.

Heap profile shows ALL the memory is of type ID.

Um... not quite sure which ID. Either ExpH.ID or... more likely... string
ID.

Let me make some more graphs, see what info, if any, I can gleam from them.

Fri Dec 21 13:17:52 EST 2012

Summary from graphs:

We are allocating a lot of IDs. That is, strings. Haskell strings, right?

Oh. I have an idea... Let's hold off on that for just a bit.

* lots of RegEx IDs. Haskell IDs.
* retained by compare.Integer. (what? why?)
* closed by Prim.Prim.sat_... Some primitive thing.
* in LAG state.

I don't understand. Who is allocating an ID?

Fri Dec 21 13:30:57 EST 2012

Oh wait! Look what happens if we turn on all profiling.

Looks like this is the ExpH ID, not the hampi ID.

For example... what if I renamed it ExpHID?

Yes. The rename verifies it. We are allocating a ton of integers.

Now, this isn't actually so surprising. For every expression we create, we
allocate a new EID.

But that doesn't make sense. Does it? Why do we allocate so much? So many?...

Who is holding on to these names?

identifyIO is.

Okay! I have a hypothesis as to what is going on.

We are holding on to every single EID.

That is, an EID is a big thunk which points to the last EID. So, for EID
500000, we have a 500000 long thunk pointing back. This is something strict
evaluation should help with...

Hmm... What if I use bang patterns to make the EID field of ExpH strict?
Shouldn't that help?

Fri Dec 21 14:21:17 EST 2012

Something I did made a difference, but I don't know what.

Let me try to identify what it was.

It didn't make a performance difference though, which is the annoying thing...
I'm not sure why. It just fixed the memory issue.

Okay. So I fixed the leak, but it didn't make any performance difference, did
it?

Fri Dec 21 14:35:05 EST 2012

Okay, well... overall the leak fix did some nice things. Including no longer
having a stack overflow.

But! We still have performance issues. And perf4 is still the benchmark we do
worst on, so let me keep on diving deeper.

Fri Dec 21 14:47:16 EST 2012

Okay, I think I know what the issue is now.

We are spending 20% of our time in __prim_eq_Integer,
and 9% of our time in __prim_leq_Integer.

The issue is, we don't do concretization of primitives.

So, for every primitive you call, we are talking about:

* box the primitive.
  Which is potentially a couple lambdas, and we know how bad boxing and
  unboxing of those are.
* the primitive itself converts ...


Okay, here's the silly thing we are doing. For every primitive, we do the
following:
 * convert all arguments from Concrete things to ExpH. (not actually done if
   the concrete thing is already ExpH, like Integer, but we had to do this
   conversion somewhere.)
 * convert all arguments from ExpH to Concrete
 * apply the primitive
 * convert result back to ExpH
 * convert result back to Concrete

That's stupid.

Okay, so I know the next thing to change. This should help performance a
bunch.

Let me try to get a pretty looking profile from which to do comparisons.

Let me put the integer primitives on it.

Fri Dec 21 15:13:14 EST 2012

I tried just the two primitives. It makes a decent difference:
   6 seconds down to 4.

I should do it in general. But to clean it up, I'll want to make some changes:

seriS should become a new class, analogous to seriEH. Only, the translation
should be much easier. It's concrete to concrete. It should be almost free.

I don't have to auto derive this to start. I can just write the instances I
need manually. Then I think I could use that to do a clean-ish way with
primitives. Unfortunately, it looks like I'll have to duplicate the
primitives. It's that, or figure out how to encode the concrete haskell
function in the primitive... That may not be so hard to do actually... Just
makes certain things annoying. Like having a list of them.

What's after the primitives? I still have things costing me. Why?

Well... again, seriS class will make conversion of RegEx much nicer, which
should help us perhaps notably?

Ug. Well... I know what to do next. I'm just kind of winding down. Let me take
a break a little and come back to this.

Fri Dec 21 21:09:55 EST 2012

Took a break, came back. It improved things a little bit.

I'm trying to understand what's the problem now. We spend most of our time and
allocation in map_lookup. But heap profiling doesn't say what we are
allocating. At least, I don't think it does.

Well... we certainly have some impressive looking functions with lots of
arguments.

Is it just a big map to look up into?

You know what may be able to solve this? An array...

But I'd rather not if I can avoid it.

Other things that might help: smarter sugar for pattern matching: try to pick
initial variable names which we like, rather than redefining a bunch of names?
I don't know why this would make a difference though. ghc ought to be able to
simplify it no problem.

Here's an idea... what if, instead of having a Map from
(Integer, Integer, ID) -> Bool, what if we had a multi-level map?

Integer -> (Integer -> (ID -> Bool))

Or, I suppose if we did it this way, it may make sense to have the ID first.

The idea is... once you find one part of the tuple, you end up doing a lot of
comparisons for equality on that first part. Much better if you just collect
together the things with the same indices. That way you can say: this group
all share this same index, so no need to worry about it.

Or! Maybe I should have the ID first, because that's a bigger distinguisher?
Because I expect less ID's than Offsets? No, that doesn't make sense. The
multi-level map does make sense... Arrays make sense too. Using an integer for
the ID at the RegEx level makes sense too.

That still doesn't explain where the allocations are coming from.

Maybe it's still the primitives? The allocation being our call to SeriS?

Was it a space leak in __lexorder? Switching from foldl to foldr seems to have
made a noticeable difference... Let me ponder this.
