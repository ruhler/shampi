
Tue Dec 18 08:46:07 EST 2012

The fix I made to seri fixed the infinite loop. So now fixN implemented in
seri works. I'm running the benchmarks though, and, sadly, it appears to to
rather noticeable worse performance wise than the previous version.

This is not really surprising... just a little discouraging.

Let's wait until we add support for sharing.. this new match implementation.
See if the exponential behavior is solved. Then ... decide. The options are:

* make seri faster (which would be good in the long run anyway)
* put most of the match implementation back in haskell
Tedious. Yucky. Error-prone. Going back and forth between haskell and seri is
painful. But it should be fast and work okay.

I suspect there are ways I could make seri faster. Some ideas are:

* Use an Int to identify constructors in ConEH. The position in the data
  structure definition. This way case match has an integer equality test
  instead of a name test.

Tue Dec 18 08:59:43 EST 2012

Anyway, next step: let me try this new match algorithm in seri.

First goal... correctness.
Second goal... handles exponential blowup in perf test.

But! Be careful. Because I expect to have a lot of entries in the map. So if
it seems prohibitively costly, switching to a better map implementation may
help significantly. So don't get dismayed too quickly.

If only I had a better way of figuring out where time was going...

Tue Dec 18 09:57:01 EST 2012

It blows up. The new match algorithm blows up on trivial examples.

Why?

* It's not lazy enough?
instead of ||, &&, and or, I should have explicitly lazy versions of these for
the state monad. This is to make it clear that: if this match succeeds or
fails, you do not have to update the cache from the resulting matches!

* The map is just too slow?
Too many lookups? Equality tests against duplicate entries?

* There's an infinite loop somewhere?

* Explicit laziness leads to case default blowup?

How can I know which of these, or what, is causing the problem?

Let me start by running through by hand, just to get a better idea of what's
going on and what I expect.

var v : 4;
cfg E :=  "()" | E E | "(" E ")" ;
assert v in E;

E4.0 = False

("()" | E E | "(" e ")")4.0
 "()"4.0
  "("0.0
  False
 False
 (E E)4.0
  E0.0              E0.0 = False
   "()"0.0
    "("0.0
    False
   False
   (E E)0.0     
    E0.0
    False
   ("(" E ")")0.0
    "("0.0
    False
   False
  False
  E1.0
  
You know what I'm missing here?
I missing this notion that: E0.x will fail for all 'x'! And we can determine
this statically. We don't need to keep evaluating E0 over and over for every
string position.

You know what else would be great? To have support for the trace primitive in
seri. I could print out a trace like above to keep track of what all things
are being tried, and more easily follow the logic. I could get a sense of
progress, infinite loopiness, all that fun stuff.

Okay, well, this is a good start.

What I want to do when I come back to this:

* figure out how to share E0.x = False, rather than duplicate it a bunch
  (perhaps a fixN-like pre-processing path?)
* add trace primitive to seri and use to follow along execution for this
  simple case.

Tue Dec 18 11:03:44 EST 2012

Here's the plan.

Keep fixN as is, and use it.

Add Variable to RegEx, with length and ID.

Step 1: Perform fixN.
 It should be modified for VariableC to go to VariableR unless the value of
 that is empty, in which case it should go to empty.

Step 2: Perform match using the map from (ID, Length) to RegEx as the
environment, caching (ID,Length,Offset) to boolean.

This should not be too difficult.

Tue Dec 18 11:58:26 EST 2012

Okay! This new match implementation seems to function correctly. How does it
do on performance?

Well... not so great.

I suspect now the problem is we have a big map, with lots of entries, and we
aren't very efficient at accessing it.

Ideas:
* Remove Empty elements from the regs map to make it faster to look into.
* Make Map implementation better.

But first I should verify this is indeed the issue I'm seeing. How to do that?

I've turned on the profiler, but I'm not sure what help it will be.

Tue Dec 18 12:09:11 EST 2012

Looking at the profile, it does look like we spend a lot of time in equality
checks, which would be the map lookup. I think we may also be spending a lot
of time doing trivial boxing/unboxing. That sort of seri overhead which I hope
not to get...

Let me think about things a bit.

Tue Dec 18 14:57:31 EST 2012

Cool! If I turn of -auto-all in both seri (the cabal files) and for shampi,
but I add explicitly the SCCs I'm interested in in SeriGen.hs, I can see where
all the time is being spent, at the granularity of seri function:

CAF            Main                        255           0    0.1    0.1   100.0  100.0
 match         SeriGen                     270           0    0.1    0.1    99.7   99.7
  map_empty    SeriGen                     276           1    0.0    0.0     0.0    0.0
  matchM       SeriGen                     272           0    5.3    5.1    99.5   99.7
   matchidM    SeriGen                     274           0   17.4   18.1    94.2   94.5
    map_insert SeriGen                     277        9285    0.5    0.5     0.5    0.5
    map_lookup SeriGen                     275       28038   76.3   76.0    76.3   76.0
 fixN          SeriGen                     265           0    0.1    0.1     0.2    0.2
  map_insert   SeriGen                     268          18    0.0    0.0     0.0    0.0
  map_empty    SeriGen                     267           1    0.0    0.0     0.0    0.0
  map_lookup   SeriGen                     266         103    0.1    0.1     0.1    0.1

Very clearly here, all the time is being spent in match. None in fix. And
almost all the time is spent in lookup, as I suspected.

This is good news. It would be nice if I could annotate all the top level seri
functions somehow... (may require ditching the haskell pretty printer if it
doesn't support annotations).

Cool. So, what are the next steps here?

* Implement a much more efficient map implementation.
Go for the binary balanced tree.

It would be worth having an easy way to turn on and off profiling for
different things... I'm not sure how to do that.

Well, I know what to do when I come back to this... assuming I have any time
to come back to this...

Tue Dec 18 17:11:19 EST 2012

Yes! Clearly almost all the time is spent in map lookup, so just improve that.

Here's a question. How much of that time is looking up in cfgs, and how much of
that time looking up in regs? Or rather... regs vs cache? Let me see if I can
figure that out.

Tue Dec 18 17:16:36 EST 2012

Looks like all the time is spent in the cache lookup. Not surprising I
suppose... As it's pretty big.

Let me switch to size 6... something that finishes. See if we have the same
problem.

Looks like it's still dominated by lookup, so this is a good one to check for
performance improvements. And especially scalability...

Tue Dec 18 17:22:13 EST 2012

Okay, so I have a baseline. What's the first step?

How about a binary tree? Don't even worry about it being balanced yet? Sure.
I can balance later.

I will need Ord. That should be doable... I'll have to give an instance for
tuple and such. That should be fine.

I hate to duplicate <= and ==... oh well.

Let me try this then.

Tue Dec 18 17:51:44 EST 2012

Guess what! Switching to a binary tree didn't make any difference in runtime.
Perhaps I need to balance it?
Perhaps I need (<) to be much more efficient...

I don't know.

Probably want to balance it next...

Tue Dec 18 18:02:45 EST 2012

You know... as far as seri overhead is concerned, much of the time seems to be
in constructing tuples, calling curry, then deconstructing tuples. And
2-tuples, to be specific, because those are what curry makes use of.

Is there some way we can get rid of this step entirely?

I don't know. Anyway, let me think about how I can implement a binary tree.

Err... Actually, let me take a break now. Take some time to think. Think about
implementing a binary tree, and think about reducing this curry cost.

Remember how curry is used:

foo p1 p2 = a
foo p3 p4 = b
...

Turns into:

foo = curry $ \x -> case x of
                        (a, b) -> case a of
                                    p1 -> ...
                        _ -> case x of
                                (c, d) -> case c of
                                             p3 -> ...
                                _ ...

What we could do instead is...

foo = \a b -> ...

Or... I suppose, in other words:

foo = \a b -> case a of
                p1 -> ...

Yes... I think that would be easy to do. We avoid calling curry so much. We
avoid packing into a tuple then unpacking from a tuple, which is really the
major cost right now! That could be big. It could be quite big...

Something to think about.

All I should need is the function which matches a set of things all together.
Pull that out of matchesE, or whereever it is, and reuse is for multi-clause
matches.

