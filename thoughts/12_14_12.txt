
Fri Dec 14 08:05:38 EST 2012

Extending runtime from 30 seconds to 15 minutes let 4 additional tests
complete. There are still 28 timeouts.

That's good to know I guess.

Anyway, at this point, it's a question of performance. First thing I want to
do is have a way of measuring performance and performance improvements.

I want it to be independent of the program for consistency, so I'll measure
time in tcl. The idea will be to produce time, and graph it normalized to the
rhampi baseline. That will tell me what things hampi can handle that I can't
handle very well. And it will say what things I handle  better.

To be fair, I should use the server/client model for rhampi. Start a server,
then have a champi program instead of rhampi which talks to the server.

Anyway, first I would like to get performance measurements.

For each test, print something like:

3 test/foo.hmp 1223 UNSAT

Fri Dec 14 09:12:57 EST 2012

For benchmarks, I don't even need the result. That makes things easier.

Now I have some numbers. But I think it's not fair to use rhampi as is. I need
a server/ mode.

Let me see if I can figure out how to use their server client mode, then get
numbers under that mode.

1. Update benchmark numbers to use rhampi server/client mode.
2. Figure out how to graph (normalized) the benchmark numbers.
   I'm thinking some sort of stacked bar plot would be nice? Not sure.
   Something. I'll play around with it.
   Get a sense of performance, which benchmarks are fast/slow, or what have
   you.
3. Understand why the paper.hmp benchmark takes 5 minutes.
   - run profiling
   - look at the generated query.
   - execute by hand to see what duplicate unnecessary work is being done.
   Come up with a plan for improving performance, and go from there.

I suspect currently almost no time is spent in the SMT queries. If that's the
case, changing SMT representation won't help. One idea I think could be good
is: have a function to compute the lengths that a RegEx could possibly match,
and use that to make quickly reduce number of partitionings attempted in
concat. But I want to really understand a case where that would help before
trying to implement.

Cool! This is exciting. I think we might just have something decent (and in a
reasonable time??) for the CAV paper.

Fri Dec 14 10:12:31 EST 2012

I made a plot. It's just a bunch of noise, even normalized. Let me try sorting
by time it takes to run the rhampi tests... if I can, and go from there.

Tried that. What we find is... tests cases that hampi is good at all take
about the same time as hampi. Harder test cases for hampi are all spread out
in terms of performance of shampi on them.

Fri Dec 14 10:28:47 EST 2012

Okay, so graphs aren't so interesting yet. In some cases we do better than
rhampi, in others worse.

I've identified a test case which appears to grow exponentially, which we
would prefer not to grow exponentially. Let me examine it more closely.

It's our old friend:

var v : N;
cfg E :=  "()" | E E | "(" E ")" ;
assert v in E;

Which grows exponentially in N.

First, let's check out the profile.

Time is spent in match.

You know what would be interesting? If I could just have SCCs for the top
level declarations in the generated seri code.

E := "()" | E E | "(" E ")"

E0 := Empty
E1 := Empty
E2 := "()"
E3 := Empty
E4 := E2 E2 | "(" E2 ")"
E5 := Empty
E6 := E2 E4 | E4 E2 | "(" E4 ")"
E7 := Empty
E8 := E2 E6 | E4 E4 | E6 E2 | "(" E6 ")"
E9 := Empty
E10 := E2 E8 | E4 E6 | E6 E4 | E8 E2 | "(" E8 ")"

What do we see here? When we fix a RegEx, we know exactly what size we expect
it to have. That is, all of our regex's have statically, known at fix time, a
width. This means to match in concat, we should know exactly partition to try.
The fixN pass expands all the possible choices.

This can reduce an exponential time down to a linear time, and so we certainly
should do it next. I expect this to solve the current problem with exponential
blowup.

How do we implement this? Here's the idea:

* Split into two kinds of regex:
One for pre-fix, and one for post-fix.

Or, another way of saying it, have a CFG and a RegEx.
They will be similar, yes, but whatever.

The RegEx will be a fixed regex. It will know exactly what size is expected.
So we'll annotate that.

fixN converts a CFG to a RegEx. Easy.

Cool! First step: let me split CFG and RegEx, get it working under the current
scheme. Then add the extra info to RegEx.

Fri Dec 14 11:23:41 EST 2012

Okay, I made the split and cleaned things up nicely.
What's the next step? Let me annotate each RegEx with its length. Hopefully
this will fix our problem with exponential blowup.

Fri Dec 14 11:36:35 EST 2012

Well... the change was made. Things are still correct. Let me try my
performance buggy case and see if it improved things... The moment of truth.

Well... it improves some. We may have gotten a few orders of magnitude. Let me
run the benchmark suite again now.

Fri Dec 14 12:52:18 EST 2012

Overall the numbers look good. Some slower. Most better. We do better than
rhampi in many cases now, even against the server/client model.

An idea to consider:
* we could end up with lots of duplicates in an or list. For example

E2 E4 and E4 E2 are exactly the same: E2 E2 E2. Why not get rid of the
duplicates and go down to just one?

This will require a canonicalization path to be effective.

It's a thought.

Anyways, what I really want to do is figure out why we still have many
examples which are slower the hampi. Especially the timeout ones, which are
more likely to be exponential kinds of things, where a solution to that could
make a big difference.

How about I look at a test case which times out, and try to figure out why.

here's a good example...

Yes. Something which takes hampi almost no time to do, but takes shampi a long
time to do, and is simple to express. And it's a straight scaling issue. So I
can try to find a good one... I can also work it out by hand and see what's
up.

Aha! Now is where things get interesting...

40% of the time is spent in sendCmds. We have a 150,000 length query.

This is a sharing problem. Because we don't preserve sharing in the generated
SMT query, the query size blows up. There is a lot of redundancy here.

I could try some things such as... turn off debugging. See if that improves
performance significantly. The other thing to do... which I really ought to do
eventually anyway, is implement my sharing proposal.

Let's see what turning off debug can do.

That solves the sendCmds problem. So that is important. It cuts the runtime

Let me add a debug flag to shampi to make it easier to control.

Fri Dec 14 13:15:36 EST 2012

Okay, I'm running the benchmarks again with debugging turned off. We'll see
what improvement, if any, that leads to.

Now... question... We saw the generated query had a lot of duplication. That
could be for a number of reasons:

* Sharing is not preserved in the elaborator.
So, if this duplication is as a result of not preserving sharing in the
elaborator, then we could change that. I don't, however, believe this is the
main cause... well, maybe. It's hard to tell. But in what seri code do we
possibly duplicate things that could blow up?

* Duplication in generated regexs
For example:

E10 := E2 E8 | E4 E6 | E6 E4 | E8 E2 | "(" E8 ")"

E10 := E2 E2 E2 E2 E2
     | E2 E2 E2 E2 E2
     | E2 E2 E2 E2 E2
     | E2 E2 E2 E2 E2
     | "(" E8 ")"

Notice: E2 E2 E2 E2 E2 is duplicated 4 times. If we don't know whether or not
one of these matches, because we have free variables, then we take the OR of
all of them, but it's all just duplicated.

This we could solve with my nub ors proposal. And it looks like here we have a
demonstration that that really could make a big difference.

* Duplication from common sub parts matching.
For example, imagine something like;

A := "a" B "c"
   | "c" B "a"

We attempt to match B at the same position twice here. That's duplicated
effort.

You almost wonder if you can do some factoring of the expression. Like, can I
rewrite this as:

A := ("a" | "c") B ("c" | "a")?
That would remove the duplication.

In fact, it seems to me this is a more general case of the OR nubing. I fear
it would be more costly though... Not sure.

The idea is... let's say I'm given two expressions. Can I factor out common
parts? Assuming we canonicalize concat.

How would this work? Let me see...

factor x y | x == y = Just x
factor (Concat a b) (Concat a' b')
 | Just ac <- factor a a' = Concat ac (Or b b')

That sort of thing.

Basically, this is a common-subexpression elimination. But, possibly, it could
be easier to do because we have to look at the right position.

The only place this is useful is when we run 'Or'. Or will try to factor out
common parts from two expressions, and replace them with a single expression.

factor :: RegEx -> RegEx -> Maybe RegEx
factor x y
 | x == y -> Just x
 | Concat ax bx <- x
 , Concat ay by <- y = 

Cases:
    ax, ay factor to az ==> Concat az (orR bx by)
    bx, by factor to bz ==> Concat (orR ax ay) bz
    ax, ay, bx, by factor to az, bz
        Shouldn't have to worry, because of recursion.

For this to work, it would be important to canonicalize ors and concats.

I don't know. What do you think? Let's look at the example which blows up to
get an idea. I know the nub thing should solve the perf1 blowup.

cfg S :=  "a" B | "b" A ;
cfg A :=  "a" | "a" S | "b" A A ;
cfg B :=  S B | "b" | "b" B B ;

S0 := {}
A0 := {}
B0 := {}

S1 := {}
A1 := "a"
B1 := "b"

S2 := "a" B1 | "b" A1   -> "ab" | "ba"
A2 := {}
B2 := {}

S3 := {}
A3 := "a" S2 | "b" A1 A1  -> "a" ("ab" | "ba") | "baa"
B3 := S2 B1 | "b" B1 B1 -> ("ab" | "ba") "b" | "bbb"

Wait. There's a problem with my factor idea. It's not correct. Is it? No! It's
not.

A := "a" B "c"
   | "c" B "a"

A := ("a" | "c") B ("c" | "a")?

The second version allows "c" B "c", which should not be allowed.

So, here's a place where caching a result would be of value, but factoring
doesn't help.

Fri Dec 14 13:56:32 EST 2012

Question... how much do you think turning on ghc optimizations could help? We
ought to be able to inline a bunch of things, right? Let me try that, see what
happens.

Turning on -O2 doubled the performance on perf2 test. That's decent. I'm
rerunning all the benchmarks with -O2 turned on, to get a sense.

I don't think it's an exponential improvement... but it ought to be able to do
a fair amount of optimizations.

After this... let me try the nub optimization, just see if it makes a big
difference. I can try it on the perf1 test, where I expect it to make a
difference, then see what effect it has on other tests.

First... let's see where the perf1 test blows up.

Fri Dec 14 14:13:54 EST 2012

I ran all the benchmarks with optimizations on. For the most part it's a
decent improvement, so I'll leave it. Some of the faster test cases got
slower, but I don't care so much about those.

Fri Dec 14 14:23:58 EST 2012

I'm getting strange behavior. Without profiling, we are much, much faster.
With profiling, we see no performance improvement. That worries me.

Let me run the benchmarks again, see if they improve because of this on the
whole.

I'm not convinced this will on the whole be an improvement. If profiling
doesn't work with it... that's odd.

Fri Dec 14 14:41:49 EST 2012

It seems to be a reasonable performance improvement (2x) on some of the, and
if worse, only by a little, so I'll keep it. It's not the silver bullet I was
looking for.

The profile shows... basically we spend a lot of time in elaboration. That's
all there is to it.

Hmm.. Well, it's worth trying some things. For example, how about I try
yices1, see how it looks?

Or try bit vectors, see how they work? That should be easy enough to try...
see if it makes a big difference or not.

Different solvers and different representations (Bit vs Integer) don't make
any difference here. It's all about reducing the match time by making use of
sharing. That's got to be what it's about.

Let me take another look at my failing performance test. I just want to get a
better feel for what we are matching against, and where we might be
duplicating work.


cfg S :=  "a" B | "b" A ;
cfg A :=  "a" | "a" S | "b" A A ;
cfg B :=  S B | "b" | "b" B B ;

SODD is Empty
A,BEVEN is Empty

S0 := {} 

A1 := "a"
B1 := "b"

S2 := "a" B1 | "b" A1

A3 := "a" S2 | "b" A1 A1
B3 := S2 B1 | "b" B1 B1

S4 := "a" B3 | "b" A3

A5 := "a" S4 | "b" A3 A3
B5 := S4 B1 | "b" B3 B3

Hmm... What do we see?

I don't know.

Fri Dec 14 16:06:41 EST 2012

Reading up from Sipser. I wonder if converting the RegEx to a state machine
could help avoid sharing. It seems like we need just a single pass through the
input. The only trouble is, how do we recognize when we reach a state we
have already seen before? Perhaps using a dynamic programming approach?

Here's how to convert a RegEx to an NFA. It's easy:

Epsilon: go to accept state.
Empty: go to fail state.
Atom, Range: if predicate matches, go to accept state.
Concat: Replace every accept state in 'a' with a non-accept state with epsilon
transition to the initial state of 'b'.
Union: Go to either of the initial states.

The next question would be, how to convert the NFA to a DFA.

Sadly, that blows up exponentially. So it's not clear to me that would help
much.

You know, the perf.hmp test still grows exponentially, and is much easier for
me to understand, so maybe I could understand things better for that case.

Hmm... Interesting. Look at E6:

E6 := E2 E4 | E4 E2 | "(" E4 ")"

I expect this to turn into:

E6 := E2 E2 E2 | E2 E2 E2 | "(" E4 ")", so we can remove redundancy... But! 

What it really looks like is:

E6 :=
    E2 (E2 E2 | "(" E2 ")")
  | (E2 E2 | "(" E2 ")") E2
  | "(" E4 ")"

Now, what we would really like, is if we saw that we could simplify this,
recognizing that we have a duplicate possibility: E2 E2 E2...

So this is where things get dangerous. What if we distribute then refactor?

E6 :=
    (E2 E2 E2 | E2 "(" E2 ")")
  | (E2 E2 E2 | "(" E2 ")" E2)
  | "(" E4 ")"

Which simplifies to:

E6 :=
    E2 E2 E2
  | E2 "(" E2 ")"
  | "(" E2 ")" E2
  | "(" E4 ")"

Be careful though, because this does introduce some duplications? Maybe...
Maybe not...

It also puts us in a position where we could do some re-factoring:

E6 :=
    E2 (E2 E2 | "(" E2 ")")
  | "(" (E2 ")" E2 | E4 ")")

Of course... if you are going to be like that, we could inline even more and
refactor...

In other words, this is looking like what I imagine a DFA would look like.

What if we reduced it to atoms? If we could somehow share that way...

Interesting. Let's say I have a different representation for regular
expressions. Let's say the representation is as follows...

RegEx :: Elem -> Maybe RegEx

But instead of a function, we'll have an explicit map...

We might need choice though... And it would be nice if we had some way to say
when we reach the end... Maybe the end always matches.

RegEx :: Elem -> [RegEx]

To match against a regular expression, you do as follows:

1. Apply the first character to figure out what the tail of the regex is.
2. If no tails, you are done. No match.
3. If some tails, match any of the tails.

We do need an accept case. Let's say each RegEx is marked as accepting or not.
If it is accepting and you have no more elements left, then you win.

In other words, I'm constructing a DFA for the Regular expression. Or rather,
an NFA... Oh. That could be important. It's an NFA...

data NFA = NFA {
    accept :: Bool,
    next :: Elem -> [NFA]
}

But really, next will be represented as...

[(Atom, NFA)]

I'm taking advantage of fixed length strings here...

data NFA = Accept | Fail | Next [(Atom, NFA)]

And each NFA is associated with a very explicit length. Every NFA describes a
language with all strings of the same length. I think this is a very important
property I want to take advantage of.

Okay, how do I build up these NFAs?

I need to support the following constructors:
    epsilonR, emptyR, concatR, orsR,

epsilonR: Accept
emptyR:   Fail
concatR a b:
    Find the tail of 'a'.  Anyone going to Accept should instead go to 'b'.
orsR a b:
    um...

The key is, can we recognize sharing.

Perhaps an easier way to construct this would be to say, given a RegEx,
compute it's NFA tail, and given that NFA tail and the RegEx, compute the full
NFA. Then the trick is, recognize sharing.

We have to recognize sharing. That's the only way this could help.

Let me look at E6 in this form.

There is clearly sharing available. Questions remain:

* Is the sharing explicit in the grammar before fix?
* Otherwise, can I discover the sharing efficiently?
* Assuming I have identified the sharing, how do I preserve that in
  elaboration?
* Assuming I preserve sharing in elaboration, how do I preserve it in SMT?

It could be a fluke... How about I change the grammar slightly:

E := "()" | E E | "[" E "]" ??

No...

Okay, How about like this.

E2 := "()"
E4 := E2 E2 | "(" E2 ")"
E6 := E2 E4 | E4 E2 | "(" E4 ")"

E6.0 involves:

E2.0        -- match E2 at position 0.
E4.2
E4.0
E2.4
E4.1

If we Expand all of these, we find:

E4.0:
E2.0
E2.1
E2.2

E4.2:
E2.2
E2.3
E2.4

In summary:

E2.0,
E2.2, E2.3, E2.4
E2.0, E2.1, E2.2
E2.4,
E2.1, E2.2, E2.3

These are all the matches we make against terminal E2 (E2 is terminal, because
it doesn't contain any choice?).

If we count them up, we find:

E2.0: 2
E2.1: 2
E2.2: 2
E2.3: 2
E2.4: 2

We are duplicating our effort. We could cut it in half.

This gives me an idea... What if we change our fix slightly... Keep track of
positions where IDs are applied...

E := "()" | E E | "(" E ")"

E0.N := Empty
E2.N := "()"
E4.N := E2.N E2.(N+2) | "(" E2.(N+1) ")"
E6.N := E2.N E4.(N+2) | E4.N E2.(N+4) | "(" E4.(N+1) ")"
E8.N := E2.N E6.(N+2) | E4.N E4.(N+4) | E6.N E2.(N+6) | "(" E6.(N+1) ")"

Okay, so let's say I'm going to evaluate E8.N. How do I want to do it?
I would want a predicate which looks as follows:

let E2_0 = ...
    E4_0 = ...
    E4_4 = ...
    E8_0 = (E2_0 && E6_2) || (E4_0 && E4_4) || (E6_0 && E2_6)
            || "("_0 && E6_1 && ")"_0)
            
in E8_0

in other words, I break down each part of a cfg into a boolean predicate.

Basically, I compile a cfg with fix into a boolean circuit.

Um... at this point, seri isn't doing very much...

But I bet it would lead to a very fast solver.

Couple this with sharing support in seri, and we will be very fast. But even
then, you probably don't need sharing support in seri, because this will be
fast enough in elaboration.

So! What's the summary?

* Yes, sharing is available explicitly in the cfg
* Yes, we can figure out efficiently what it is
* Yes, we can express this to the seri elaborator
* Yes, with support for sharing in the seri elaborator, this sharing will
  be preserved in the generated smts. 

I suspect this would lead to a very fast solver. Very very very fast.

Notice: seri is important for this. For inlining and such. But it's used in a
different way. The way seri is used is just as any symbolic thing or dsel. I
generating a seri expression with explicit sharing. So fixN would return,
instead of a RegEx, an S.Bool.

That doesn't really help much for seri then, does it...

